// Package parser is generated by gogll. Do not edit.
package parser

import (
	"bytes"
	"fmt"
	"sort"
	"strings"

	"eggr/lexer"
	"eggr/parser/bsr"
	"eggr/parser/slot"
	"eggr/parser/symbols"
	"eggr/token"
)

type parser struct {
	cI int

	R *descriptors
	U *descriptors

	popped   map[poppedNode]bool
	crf      map[clusterNode][]*crfNode
	crfNodes map[crfNode]*crfNode

	lex         *lexer.Lexer
	parseErrors []*Error

	bsrSet *bsr.Set
}

func newParser(l *lexer.Lexer) *parser {
	return &parser{
		cI:     0,
		lex:    l,
		R:      &descriptors{},
		U:      &descriptors{},
		popped: make(map[poppedNode]bool),
		crf: map[clusterNode][]*crfNode{
			{symbols.NT_Grammar, 0}: {},
		},
		crfNodes:    map[crfNode]*crfNode{},
		bsrSet:      bsr.New(symbols.NT_Grammar, l),
		parseErrors: nil,
	}
}

// Parse returns the BSR set containing the parse forest.
// If the parse was successfull []*Error is nil
func Parse(l *lexer.Lexer) (*bsr.Set, []*Error) {
	return newParser(l).parse()
}

func (p *parser) parse() (*bsr.Set, []*Error) {
	var L slot.Label
	m, cU := len(p.lex.Tokens)-1, 0
	p.ntAdd(symbols.NT_Grammar, 0)
	// p.DumpDescriptors()
	for !p.R.empty() {
		L, cU, p.cI = p.R.remove()

		// fmt.Println()
		// fmt.Printf("L:%s, cI:%d, I[p.cI]:%s, cU:%d\n", L, p.cI, p.lex.Tokens[p.cI], cU)
		// p.DumpDescriptors()

		switch L {
		case slot.AND0R0: // AND : ∙& WS

			p.bsrSet.Add(slot.AND0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.AND0R1) {
				p.parseError(slot.AND0R1, p.cI, first[slot.AND0R1])
				break
			}

			p.call(slot.AND0R2, cU, p.cI)
		case slot.AND0R2: // AND : & WS ∙

			if p.follow(symbols.NT_AND) {
				p.rtn(symbols.NT_AND, cU, p.cI)
			} else {
				p.parseError(slot.AND0R0, p.cI, followSets[symbols.NT_AND])
			}
		case slot.ANY0R0: // ANY : ∙. WS

			p.bsrSet.Add(slot.ANY0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.ANY0R1) {
				p.parseError(slot.ANY0R1, p.cI, first[slot.ANY0R1])
				break
			}

			p.call(slot.ANY0R2, cU, p.cI)
		case slot.ANY0R2: // ANY : . WS ∙

			if p.follow(symbols.NT_ANY) {
				p.rtn(symbols.NT_ANY, cU, p.cI)
			} else {
				p.parseError(slot.ANY0R0, p.cI, followSets[symbols.NT_ANY])
			}
		case slot.CLOSE0R0: // CLOSE : ∙( WS

			p.bsrSet.Add(slot.CLOSE0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.CLOSE0R1) {
				p.parseError(slot.CLOSE0R1, p.cI, first[slot.CLOSE0R1])
				break
			}

			p.call(slot.CLOSE0R2, cU, p.cI)
		case slot.CLOSE0R2: // CLOSE : ( WS ∙

			if p.follow(symbols.NT_CLOSE) {
				p.rtn(symbols.NT_CLOSE, cU, p.cI)
			} else {
				p.parseError(slot.CLOSE0R0, p.cI, followSets[symbols.NT_CLOSE])
			}
		case slot.CharClass0R0: // CharClass : ∙[ UnclosedChars ] WS

			p.bsrSet.Add(slot.CharClass0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.CharClass0R1) {
				p.parseError(slot.CharClass0R1, p.cI, first[slot.CharClass0R1])
				break
			}

			p.call(slot.CharClass0R2, cU, p.cI)
		case slot.CharClass0R2: // CharClass : [ UnclosedChars ∙] WS

			if !p.testSelect(slot.CharClass0R2) {
				p.parseError(slot.CharClass0R2, p.cI, first[slot.CharClass0R2])
				break
			}

			p.bsrSet.Add(slot.CharClass0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.CharClass0R3) {
				p.parseError(slot.CharClass0R3, p.cI, first[slot.CharClass0R3])
				break
			}

			p.call(slot.CharClass0R4, cU, p.cI)
		case slot.CharClass0R4: // CharClass : [ UnclosedChars ] WS ∙

			if p.follow(symbols.NT_CharClass) {
				p.rtn(symbols.NT_CharClass, cU, p.cI)
			} else {
				p.parseError(slot.CharClass0R0, p.cI, followSets[symbols.NT_CharClass])
			}
		case slot.CharLiteral0R0: // CharLiteral : ∙sQuote Character sQuote

			p.bsrSet.Add(slot.CharLiteral0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.CharLiteral0R1) {
				p.parseError(slot.CharLiteral0R1, p.cI, first[slot.CharLiteral0R1])
				break
			}

			p.call(slot.CharLiteral0R2, cU, p.cI)
		case slot.CharLiteral0R2: // CharLiteral : sQuote Character ∙sQuote

			if !p.testSelect(slot.CharLiteral0R2) {
				p.parseError(slot.CharLiteral0R2, p.cI, first[slot.CharLiteral0R2])
				break
			}

			p.bsrSet.Add(slot.CharLiteral0R3, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_CharLiteral) {
				p.rtn(symbols.NT_CharLiteral, cU, p.cI)
			} else {
				p.parseError(slot.CharLiteral0R0, p.cI, followSets[symbols.NT_CharLiteral])
			}
		case slot.Character0R0: // Character : ∙notQuotesEsc

			p.bsrSet.Add(slot.Character0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Character) {
				p.rtn(symbols.NT_Character, cU, p.cI)
			} else {
				p.parseError(slot.Character0R0, p.cI, followSets[symbols.NT_Character])
			}
		case slot.Character1R0: // Character : ∙esc

			p.bsrSet.Add(slot.Character1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Character) {
				p.rtn(symbols.NT_Character, cU, p.cI)
			} else {
				p.parseError(slot.Character1R0, p.cI, followSets[symbols.NT_Character])
			}
		case slot.Choice0R0: // Choice : ∙Sequence RepPipedSeq0x

			p.call(slot.Choice0R1, cU, p.cI)
		case slot.Choice0R1: // Choice : Sequence ∙RepPipedSeq0x

			if !p.testSelect(slot.Choice0R1) {
				p.parseError(slot.Choice0R1, p.cI, first[slot.Choice0R1])
				break
			}

			p.call(slot.Choice0R2, cU, p.cI)
		case slot.Choice0R2: // Choice : Sequence RepPipedSeq0x ∙

			if p.follow(symbols.NT_Choice) {
				p.rtn(symbols.NT_Choice, cU, p.cI)
			} else {
				p.parseError(slot.Choice0R0, p.cI, followSets[symbols.NT_Choice])
			}
		case slot.EMPTY0R0: // EMPTY : ∙; WS

			p.bsrSet.Add(slot.EMPTY0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.EMPTY0R1) {
				p.parseError(slot.EMPTY0R1, p.cI, first[slot.EMPTY0R1])
				break
			}

			p.call(slot.EMPTY0R2, cU, p.cI)
		case slot.EMPTY0R2: // EMPTY : ; WS ∙

			if p.follow(symbols.NT_EMPTY) {
				p.rtn(symbols.NT_EMPTY, cU, p.cI)
			} else {
				p.parseError(slot.EMPTY0R0, p.cI, followSets[symbols.NT_EMPTY])
			}
		case slot.EQUAL0R0: // EQUAL : ∙= WS

			p.bsrSet.Add(slot.EQUAL0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.EQUAL0R1) {
				p.parseError(slot.EQUAL0R1, p.cI, first[slot.EQUAL0R1])
				break
			}

			p.call(slot.EQUAL0R2, cU, p.cI)
		case slot.EQUAL0R2: // EQUAL : = WS ∙

			if p.follow(symbols.NT_EQUAL) {
				p.rtn(symbols.NT_EQUAL, cU, p.cI)
			} else {
				p.parseError(slot.EQUAL0R0, p.cI, followSets[symbols.NT_EQUAL])
			}
		case slot.Expression0R0: // Expression : ∙AND Primary

			p.call(slot.Expression0R1, cU, p.cI)
		case slot.Expression0R1: // Expression : AND ∙Primary

			if !p.testSelect(slot.Expression0R1) {
				p.parseError(slot.Expression0R1, p.cI, first[slot.Expression0R1])
				break
			}

			p.call(slot.Expression0R2, cU, p.cI)
		case slot.Expression0R2: // Expression : AND Primary ∙

			if p.follow(symbols.NT_Expression) {
				p.rtn(symbols.NT_Expression, cU, p.cI)
			} else {
				p.parseError(slot.Expression0R0, p.cI, followSets[symbols.NT_Expression])
			}
		case slot.Expression1R0: // Expression : ∙NOT Primary

			p.call(slot.Expression1R1, cU, p.cI)
		case slot.Expression1R1: // Expression : NOT ∙Primary

			if !p.testSelect(slot.Expression1R1) {
				p.parseError(slot.Expression1R1, p.cI, first[slot.Expression1R1])
				break
			}

			p.call(slot.Expression1R2, cU, p.cI)
		case slot.Expression1R2: // Expression : NOT Primary ∙

			if p.follow(symbols.NT_Expression) {
				p.rtn(symbols.NT_Expression, cU, p.cI)
			} else {
				p.parseError(slot.Expression1R0, p.cI, followSets[symbols.NT_Expression])
			}
		case slot.Expression2R0: // Expression : ∙Primary OptStarPlus

			p.call(slot.Expression2R1, cU, p.cI)
		case slot.Expression2R1: // Expression : Primary ∙OptStarPlus

			if !p.testSelect(slot.Expression2R1) {
				p.parseError(slot.Expression2R1, p.cI, first[slot.Expression2R1])
				break
			}

			p.call(slot.Expression2R2, cU, p.cI)
		case slot.Expression2R2: // Expression : Primary OptStarPlus ∙

			if p.follow(symbols.NT_Expression) {
				p.rtn(symbols.NT_Expression, cU, p.cI)
			} else {
				p.parseError(slot.Expression2R0, p.cI, followSets[symbols.NT_Expression])
			}
		case slot.Grammar0R0: // Grammar : ∙WS Rule RepRule0x

			p.call(slot.Grammar0R1, cU, p.cI)
		case slot.Grammar0R1: // Grammar : WS ∙Rule RepRule0x

			if !p.testSelect(slot.Grammar0R1) {
				p.parseError(slot.Grammar0R1, p.cI, first[slot.Grammar0R1])
				break
			}

			p.call(slot.Grammar0R2, cU, p.cI)
		case slot.Grammar0R2: // Grammar : WS Rule ∙RepRule0x

			if !p.testSelect(slot.Grammar0R2) {
				p.parseError(slot.Grammar0R2, p.cI, first[slot.Grammar0R2])
				break
			}

			p.call(slot.Grammar0R3, cU, p.cI)
		case slot.Grammar0R3: // Grammar : WS Rule RepRule0x ∙

			if p.follow(symbols.NT_Grammar) {
				p.rtn(symbols.NT_Grammar, cU, p.cI)
			} else {
				p.parseError(slot.Grammar0R0, p.cI, followSets[symbols.NT_Grammar])
			}
		case slot.Identifier0R0: // Identifier : ∙LetWS LetOrNum0x WS

			p.call(slot.Identifier0R1, cU, p.cI)
		case slot.Identifier0R1: // Identifier : LetWS ∙LetOrNum0x WS

			if !p.testSelect(slot.Identifier0R1) {
				p.parseError(slot.Identifier0R1, p.cI, first[slot.Identifier0R1])
				break
			}

			p.call(slot.Identifier0R2, cU, p.cI)
		case slot.Identifier0R2: // Identifier : LetWS LetOrNum0x ∙WS

			if !p.testSelect(slot.Identifier0R2) {
				p.parseError(slot.Identifier0R2, p.cI, first[slot.Identifier0R2])
				break
			}

			p.call(slot.Identifier0R3, cU, p.cI)
		case slot.Identifier0R3: // Identifier : LetWS LetOrNum0x WS ∙

			if p.follow(symbols.NT_Identifier) {
				p.rtn(symbols.NT_Identifier, cU, p.cI)
			} else {
				p.parseError(slot.Identifier0R0, p.cI, followSets[symbols.NT_Identifier])
			}
		case slot.LetOrNum0R0: // LetOrNum : ∙let

			p.bsrSet.Add(slot.LetOrNum0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LetOrNum) {
				p.rtn(symbols.NT_LetOrNum, cU, p.cI)
			} else {
				p.parseError(slot.LetOrNum0R0, p.cI, followSets[symbols.NT_LetOrNum])
			}
		case slot.LetOrNum1R0: // LetOrNum : ∙num

			p.bsrSet.Add(slot.LetOrNum1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LetOrNum) {
				p.rtn(symbols.NT_LetOrNum, cU, p.cI)
			} else {
				p.parseError(slot.LetOrNum1R0, p.cI, followSets[symbols.NT_LetOrNum])
			}
		case slot.LetOrNum2R0: // LetOrNum : ∙WS

			p.call(slot.LetOrNum2R1, cU, p.cI)
		case slot.LetOrNum2R1: // LetOrNum : WS ∙

			if p.follow(symbols.NT_LetOrNum) {
				p.rtn(symbols.NT_LetOrNum, cU, p.cI)
			} else {
				p.parseError(slot.LetOrNum2R0, p.cI, followSets[symbols.NT_LetOrNum])
			}
		case slot.LetOrNum0x0R0: // LetOrNum0x : ∙LetOrNum LetOrNum0x

			p.call(slot.LetOrNum0x0R1, cU, p.cI)
		case slot.LetOrNum0x0R1: // LetOrNum0x : LetOrNum ∙LetOrNum0x

			if !p.testSelect(slot.LetOrNum0x0R1) {
				p.parseError(slot.LetOrNum0x0R1, p.cI, first[slot.LetOrNum0x0R1])
				break
			}

			p.call(slot.LetOrNum0x0R2, cU, p.cI)
		case slot.LetOrNum0x0R2: // LetOrNum0x : LetOrNum LetOrNum0x ∙

			if p.follow(symbols.NT_LetOrNum0x) {
				p.rtn(symbols.NT_LetOrNum0x, cU, p.cI)
			} else {
				p.parseError(slot.LetOrNum0x0R0, p.cI, followSets[symbols.NT_LetOrNum0x])
			}
		case slot.LetOrNum0x1R0: // LetOrNum0x : ∙EMPTY

			p.call(slot.LetOrNum0x1R1, cU, p.cI)
		case slot.LetOrNum0x1R1: // LetOrNum0x : EMPTY ∙

			if p.follow(symbols.NT_LetOrNum0x) {
				p.rtn(symbols.NT_LetOrNum0x, cU, p.cI)
			} else {
				p.parseError(slot.LetOrNum0x1R0, p.cI, followSets[symbols.NT_LetOrNum0x])
			}
		case slot.LetWS0R0: // LetWS : ∙let

			p.bsrSet.Add(slot.LetWS0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LetWS) {
				p.rtn(symbols.NT_LetWS, cU, p.cI)
			} else {
				p.parseError(slot.LetWS0R0, p.cI, followSets[symbols.NT_LetWS])
			}
		case slot.LetWS1R0: // LetWS : ∙WS

			p.call(slot.LetWS1R1, cU, p.cI)
		case slot.LetWS1R1: // LetWS : WS ∙

			if p.follow(symbols.NT_LetWS) {
				p.rtn(symbols.NT_LetWS, cU, p.cI)
			} else {
				p.parseError(slot.LetWS1R0, p.cI, followSets[symbols.NT_LetWS])
			}
		case slot.LineOrBlock0R0: // LineOrBlock : ∙lineComment

			p.bsrSet.Add(slot.LineOrBlock0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineOrBlock) {
				p.rtn(symbols.NT_LineOrBlock, cU, p.cI)
			} else {
				p.parseError(slot.LineOrBlock0R0, p.cI, followSets[symbols.NT_LineOrBlock])
			}
		case slot.LineOrBlock1R0: // LineOrBlock : ∙blockComment

			p.bsrSet.Add(slot.LineOrBlock1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineOrBlock) {
				p.rtn(symbols.NT_LineOrBlock, cU, p.cI)
			} else {
				p.parseError(slot.LineOrBlock1R0, p.cI, followSets[symbols.NT_LineOrBlock])
			}
		case slot.NEQUAL0R0: // NEQUAL : ∙neq WS

			p.bsrSet.Add(slot.NEQUAL0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.NEQUAL0R1) {
				p.parseError(slot.NEQUAL0R1, p.cI, first[slot.NEQUAL0R1])
				break
			}

			p.call(slot.NEQUAL0R2, cU, p.cI)
		case slot.NEQUAL0R2: // NEQUAL : neq WS ∙

			if p.follow(symbols.NT_NEQUAL) {
				p.rtn(symbols.NT_NEQUAL, cU, p.cI)
			} else {
				p.parseError(slot.NEQUAL0R0, p.cI, followSets[symbols.NT_NEQUAL])
			}
		case slot.NOT0R0: // NOT : ∙! WS

			p.bsrSet.Add(slot.NOT0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.NOT0R1) {
				p.parseError(slot.NOT0R1, p.cI, first[slot.NOT0R1])
				break
			}

			p.call(slot.NOT0R2, cU, p.cI)
		case slot.NOT0R2: // NOT : ! WS ∙

			if p.follow(symbols.NT_NOT) {
				p.rtn(symbols.NT_NOT, cU, p.cI)
			} else {
				p.parseError(slot.NOT0R0, p.cI, followSets[symbols.NT_NOT])
			}
		case slot.OPEN0R0: // OPEN : ∙( WS

			p.bsrSet.Add(slot.OPEN0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.OPEN0R1) {
				p.parseError(slot.OPEN0R1, p.cI, first[slot.OPEN0R1])
				break
			}

			p.call(slot.OPEN0R2, cU, p.cI)
		case slot.OPEN0R2: // OPEN : ( WS ∙

			if p.follow(symbols.NT_OPEN) {
				p.rtn(symbols.NT_OPEN, cU, p.cI)
			} else {
				p.parseError(slot.OPEN0R0, p.cI, followSets[symbols.NT_OPEN])
			}
		case slot.OPT0R0: // OPT : ∙? WS

			p.bsrSet.Add(slot.OPT0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.OPT0R1) {
				p.parseError(slot.OPT0R1, p.cI, first[slot.OPT0R1])
				break
			}

			p.call(slot.OPT0R2, cU, p.cI)
		case slot.OPT0R2: // OPT : ? WS ∙

			if p.follow(symbols.NT_OPT) {
				p.rtn(symbols.NT_OPT, cU, p.cI)
			} else {
				p.parseError(slot.OPT0R0, p.cI, followSets[symbols.NT_OPT])
			}
		case slot.OptStarPlus0R0: // OptStarPlus : ∙OPT

			p.call(slot.OptStarPlus0R1, cU, p.cI)
		case slot.OptStarPlus0R1: // OptStarPlus : OPT ∙

			if p.follow(symbols.NT_OptStarPlus) {
				p.rtn(symbols.NT_OptStarPlus, cU, p.cI)
			} else {
				p.parseError(slot.OptStarPlus0R0, p.cI, followSets[symbols.NT_OptStarPlus])
			}
		case slot.OptStarPlus1R0: // OptStarPlus : ∙STAR

			p.call(slot.OptStarPlus1R1, cU, p.cI)
		case slot.OptStarPlus1R1: // OptStarPlus : STAR ∙

			if p.follow(symbols.NT_OptStarPlus) {
				p.rtn(symbols.NT_OptStarPlus, cU, p.cI)
			} else {
				p.parseError(slot.OptStarPlus1R0, p.cI, followSets[symbols.NT_OptStarPlus])
			}
		case slot.OptStarPlus2R0: // OptStarPlus : ∙PLUS

			p.call(slot.OptStarPlus2R1, cU, p.cI)
		case slot.OptStarPlus2R1: // OptStarPlus : PLUS ∙

			if p.follow(symbols.NT_OptStarPlus) {
				p.rtn(symbols.NT_OptStarPlus, cU, p.cI)
			} else {
				p.parseError(slot.OptStarPlus2R0, p.cI, followSets[symbols.NT_OptStarPlus])
			}
		case slot.OptStarPlus3R0: // OptStarPlus : ∙
			p.bsrSet.AddEmpty(slot.OptStarPlus3R0, p.cI)

			if p.follow(symbols.NT_OptStarPlus) {
				p.rtn(symbols.NT_OptStarPlus, cU, p.cI)
			} else {
				p.parseError(slot.OptStarPlus3R0, p.cI, followSets[symbols.NT_OptStarPlus])
			}
		case slot.PIPE0R0: // PIPE : ∙| WS

			p.bsrSet.Add(slot.PIPE0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.PIPE0R1) {
				p.parseError(slot.PIPE0R1, p.cI, first[slot.PIPE0R1])
				break
			}

			p.call(slot.PIPE0R2, cU, p.cI)
		case slot.PIPE0R2: // PIPE : | WS ∙

			if p.follow(symbols.NT_PIPE) {
				p.rtn(symbols.NT_PIPE, cU, p.cI)
			} else {
				p.parseError(slot.PIPE0R0, p.cI, followSets[symbols.NT_PIPE])
			}
		case slot.PLUS0R0: // PLUS : ∙+ WS

			p.bsrSet.Add(slot.PLUS0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.PLUS0R1) {
				p.parseError(slot.PLUS0R1, p.cI, first[slot.PLUS0R1])
				break
			}

			p.call(slot.PLUS0R2, cU, p.cI)
		case slot.PLUS0R2: // PLUS : + WS ∙

			if p.follow(symbols.NT_PLUS) {
				p.rtn(symbols.NT_PLUS, cU, p.cI)
			} else {
				p.parseError(slot.PLUS0R0, p.cI, followSets[symbols.NT_PLUS])
			}
		case slot.Primary0R0: // Primary : ∙Identifier NEQUAL

			p.call(slot.Primary0R1, cU, p.cI)
		case slot.Primary0R1: // Primary : Identifier ∙NEQUAL

			if !p.testSelect(slot.Primary0R1) {
				p.parseError(slot.Primary0R1, p.cI, first[slot.Primary0R1])
				break
			}

			p.call(slot.Primary0R2, cU, p.cI)
		case slot.Primary0R2: // Primary : Identifier NEQUAL ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary0R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary1R0: // Primary : ∙OPEN Choice CLOSE

			p.call(slot.Primary1R1, cU, p.cI)
		case slot.Primary1R1: // Primary : OPEN ∙Choice CLOSE

			if !p.testSelect(slot.Primary1R1) {
				p.parseError(slot.Primary1R1, p.cI, first[slot.Primary1R1])
				break
			}

			p.call(slot.Primary1R2, cU, p.cI)
		case slot.Primary1R2: // Primary : OPEN Choice ∙CLOSE

			if !p.testSelect(slot.Primary1R2) {
				p.parseError(slot.Primary1R2, p.cI, first[slot.Primary1R2])
				break
			}

			p.call(slot.Primary1R3, cU, p.cI)
		case slot.Primary1R3: // Primary : OPEN Choice CLOSE ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary1R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary2R0: // Primary : ∙StringLiteral

			p.call(slot.Primary2R1, cU, p.cI)
		case slot.Primary2R1: // Primary : StringLiteral ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary2R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary3R0: // Primary : ∙CharLiteral

			p.call(slot.Primary3R1, cU, p.cI)
		case slot.Primary3R1: // Primary : CharLiteral ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary3R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary4R0: // Primary : ∙CharClass

			p.call(slot.Primary4R1, cU, p.cI)
		case slot.Primary4R1: // Primary : CharClass ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary4R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary5R0: // Primary : ∙ANY

			p.call(slot.Primary5R1, cU, p.cI)
		case slot.Primary5R1: // Primary : ANY ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary5R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.Primary6R0: // Primary : ∙EMPTY

			p.call(slot.Primary6R1, cU, p.cI)
		case slot.Primary6R1: // Primary : EMPTY ∙

			if p.follow(symbols.NT_Primary) {
				p.rtn(symbols.NT_Primary, cU, p.cI)
			} else {
				p.parseError(slot.Primary6R0, p.cI, followSets[symbols.NT_Primary])
			}
		case slot.RepExpr0x0R0: // RepExpr0x : ∙Expression RepExpr0x

			p.call(slot.RepExpr0x0R1, cU, p.cI)
		case slot.RepExpr0x0R1: // RepExpr0x : Expression ∙RepExpr0x

			if !p.testSelect(slot.RepExpr0x0R1) {
				p.parseError(slot.RepExpr0x0R1, p.cI, first[slot.RepExpr0x0R1])
				break
			}

			p.call(slot.RepExpr0x0R2, cU, p.cI)
		case slot.RepExpr0x0R2: // RepExpr0x : Expression RepExpr0x ∙

			if p.follow(symbols.NT_RepExpr0x) {
				p.rtn(symbols.NT_RepExpr0x, cU, p.cI)
			} else {
				p.parseError(slot.RepExpr0x0R0, p.cI, followSets[symbols.NT_RepExpr0x])
			}
		case slot.RepExpr0x1R0: // RepExpr0x : ∙
			p.bsrSet.AddEmpty(slot.RepExpr0x1R0, p.cI)

			if p.follow(symbols.NT_RepExpr0x) {
				p.rtn(symbols.NT_RepExpr0x, cU, p.cI)
			} else {
				p.parseError(slot.RepExpr0x1R0, p.cI, followSets[symbols.NT_RepExpr0x])
			}
		case slot.RepPipedSeq0x0R0: // RepPipedSeq0x : ∙PIPE Sequence RepPipedSeq0x

			p.call(slot.RepPipedSeq0x0R1, cU, p.cI)
		case slot.RepPipedSeq0x0R1: // RepPipedSeq0x : PIPE ∙Sequence RepPipedSeq0x

			if !p.testSelect(slot.RepPipedSeq0x0R1) {
				p.parseError(slot.RepPipedSeq0x0R1, p.cI, first[slot.RepPipedSeq0x0R1])
				break
			}

			p.call(slot.RepPipedSeq0x0R2, cU, p.cI)
		case slot.RepPipedSeq0x0R2: // RepPipedSeq0x : PIPE Sequence ∙RepPipedSeq0x

			if !p.testSelect(slot.RepPipedSeq0x0R2) {
				p.parseError(slot.RepPipedSeq0x0R2, p.cI, first[slot.RepPipedSeq0x0R2])
				break
			}

			p.call(slot.RepPipedSeq0x0R3, cU, p.cI)
		case slot.RepPipedSeq0x0R3: // RepPipedSeq0x : PIPE Sequence RepPipedSeq0x ∙

			if p.follow(symbols.NT_RepPipedSeq0x) {
				p.rtn(symbols.NT_RepPipedSeq0x, cU, p.cI)
			} else {
				p.parseError(slot.RepPipedSeq0x0R0, p.cI, followSets[symbols.NT_RepPipedSeq0x])
			}
		case slot.RepPipedSeq0x1R0: // RepPipedSeq0x : ∙
			p.bsrSet.AddEmpty(slot.RepPipedSeq0x1R0, p.cI)

			if p.follow(symbols.NT_RepPipedSeq0x) {
				p.rtn(symbols.NT_RepPipedSeq0x, cU, p.cI)
			} else {
				p.parseError(slot.RepPipedSeq0x1R0, p.cI, followSets[symbols.NT_RepPipedSeq0x])
			}
		case slot.RepRule0x0R0: // RepRule0x : ∙Rule RepRule0x

			p.call(slot.RepRule0x0R1, cU, p.cI)
		case slot.RepRule0x0R1: // RepRule0x : Rule ∙RepRule0x

			if !p.testSelect(slot.RepRule0x0R1) {
				p.parseError(slot.RepRule0x0R1, p.cI, first[slot.RepRule0x0R1])
				break
			}

			p.call(slot.RepRule0x0R2, cU, p.cI)
		case slot.RepRule0x0R2: // RepRule0x : Rule RepRule0x ∙

			if p.follow(symbols.NT_RepRule0x) {
				p.rtn(symbols.NT_RepRule0x, cU, p.cI)
			} else {
				p.parseError(slot.RepRule0x0R0, p.cI, followSets[symbols.NT_RepRule0x])
			}
		case slot.RepRule0x1R0: // RepRule0x : ∙
			p.bsrSet.AddEmpty(slot.RepRule0x1R0, p.cI)

			if p.follow(symbols.NT_RepRule0x) {
				p.rtn(symbols.NT_RepRule0x, cU, p.cI)
			} else {
				p.parseError(slot.RepRule0x1R0, p.cI, followSets[symbols.NT_RepRule0x])
			}
		case slot.Rule0R0: // Rule : ∙Identifier EQUAL Choice

			p.call(slot.Rule0R1, cU, p.cI)
		case slot.Rule0R1: // Rule : Identifier ∙EQUAL Choice

			if !p.testSelect(slot.Rule0R1) {
				p.parseError(slot.Rule0R1, p.cI, first[slot.Rule0R1])
				break
			}

			p.call(slot.Rule0R2, cU, p.cI)
		case slot.Rule0R2: // Rule : Identifier EQUAL ∙Choice

			if !p.testSelect(slot.Rule0R2) {
				p.parseError(slot.Rule0R2, p.cI, first[slot.Rule0R2])
				break
			}

			p.call(slot.Rule0R3, cU, p.cI)
		case slot.Rule0R3: // Rule : Identifier EQUAL Choice ∙

			if p.follow(symbols.NT_Rule) {
				p.rtn(symbols.NT_Rule, cU, p.cI)
			} else {
				p.parseError(slot.Rule0R0, p.cI, followSets[symbols.NT_Rule])
			}
		case slot.STAR0R0: // STAR : ∙* WS

			p.bsrSet.Add(slot.STAR0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.STAR0R1) {
				p.parseError(slot.STAR0R1, p.cI, first[slot.STAR0R1])
				break
			}

			p.call(slot.STAR0R2, cU, p.cI)
		case slot.STAR0R2: // STAR : * WS ∙

			if p.follow(symbols.NT_STAR) {
				p.rtn(symbols.NT_STAR, cU, p.cI)
			} else {
				p.parseError(slot.STAR0R0, p.cI, followSets[symbols.NT_STAR])
			}
		case slot.Sequence0R0: // Sequence : ∙Expression RepExpr0x

			p.call(slot.Sequence0R1, cU, p.cI)
		case slot.Sequence0R1: // Sequence : Expression ∙RepExpr0x

			if !p.testSelect(slot.Sequence0R1) {
				p.parseError(slot.Sequence0R1, p.cI, first[slot.Sequence0R1])
				break
			}

			p.call(slot.Sequence0R2, cU, p.cI)
		case slot.Sequence0R2: // Sequence : Expression RepExpr0x ∙

			if p.follow(symbols.NT_Sequence) {
				p.rtn(symbols.NT_Sequence, cU, p.cI)
			} else {
				p.parseError(slot.Sequence0R0, p.cI, followSets[symbols.NT_Sequence])
			}
		case slot.SpaceOrComment0R0: // SpaceOrComment : ∙space

			p.bsrSet.Add(slot.SpaceOrComment0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_SpaceOrComment) {
				p.rtn(symbols.NT_SpaceOrComment, cU, p.cI)
			} else {
				p.parseError(slot.SpaceOrComment0R0, p.cI, followSets[symbols.NT_SpaceOrComment])
			}
		case slot.SpaceOrComment1R0: // SpaceOrComment : ∙LineOrBlock

			p.call(slot.SpaceOrComment1R1, cU, p.cI)
		case slot.SpaceOrComment1R1: // SpaceOrComment : LineOrBlock ∙

			if p.follow(symbols.NT_SpaceOrComment) {
				p.rtn(symbols.NT_SpaceOrComment, cU, p.cI)
			} else {
				p.parseError(slot.SpaceOrComment1R0, p.cI, followSets[symbols.NT_SpaceOrComment])
			}
		case slot.String0R0: // String : ∙Character String

			p.call(slot.String0R1, cU, p.cI)
		case slot.String0R1: // String : Character ∙String

			if !p.testSelect(slot.String0R1) {
				p.parseError(slot.String0R1, p.cI, first[slot.String0R1])
				break
			}

			p.call(slot.String0R2, cU, p.cI)
		case slot.String0R2: // String : Character String ∙

			if p.follow(symbols.NT_String) {
				p.rtn(symbols.NT_String, cU, p.cI)
			} else {
				p.parseError(slot.String0R0, p.cI, followSets[symbols.NT_String])
			}
		case slot.String1R0: // String : ∙
			p.bsrSet.AddEmpty(slot.String1R0, p.cI)

			if p.follow(symbols.NT_String) {
				p.rtn(symbols.NT_String, cU, p.cI)
			} else {
				p.parseError(slot.String1R0, p.cI, followSets[symbols.NT_String])
			}
		case slot.StringLiteral0R0: // StringLiteral : ∙dQuote String dQuote WS

			p.bsrSet.Add(slot.StringLiteral0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.StringLiteral0R1) {
				p.parseError(slot.StringLiteral0R1, p.cI, first[slot.StringLiteral0R1])
				break
			}

			p.call(slot.StringLiteral0R2, cU, p.cI)
		case slot.StringLiteral0R2: // StringLiteral : dQuote String ∙dQuote WS

			if !p.testSelect(slot.StringLiteral0R2) {
				p.parseError(slot.StringLiteral0R2, p.cI, first[slot.StringLiteral0R2])
				break
			}

			p.bsrSet.Add(slot.StringLiteral0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.StringLiteral0R3) {
				p.parseError(slot.StringLiteral0R3, p.cI, first[slot.StringLiteral0R3])
				break
			}

			p.call(slot.StringLiteral0R4, cU, p.cI)
		case slot.StringLiteral0R4: // StringLiteral : dQuote String dQuote WS ∙

			if p.follow(symbols.NT_StringLiteral) {
				p.rtn(symbols.NT_StringLiteral, cU, p.cI)
			} else {
				p.parseError(slot.StringLiteral0R0, p.cI, followSets[symbols.NT_StringLiteral])
			}
		case slot.UnclosedChar0R0: // UnclosedChar : ∙notSqBk Character

			p.bsrSet.Add(slot.UnclosedChar0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.UnclosedChar0R1) {
				p.parseError(slot.UnclosedChar0R1, p.cI, first[slot.UnclosedChar0R1])
				break
			}

			p.call(slot.UnclosedChar0R2, cU, p.cI)
		case slot.UnclosedChar0R2: // UnclosedChar : notSqBk Character ∙

			if p.follow(symbols.NT_UnclosedChar) {
				p.rtn(symbols.NT_UnclosedChar, cU, p.cI)
			} else {
				p.parseError(slot.UnclosedChar0R0, p.cI, followSets[symbols.NT_UnclosedChar])
			}
		case slot.UnclosedChars0R0: // UnclosedChars : ∙UnclosedChar UnclosedChars

			p.call(slot.UnclosedChars0R1, cU, p.cI)
		case slot.UnclosedChars0R1: // UnclosedChars : UnclosedChar ∙UnclosedChars

			if !p.testSelect(slot.UnclosedChars0R1) {
				p.parseError(slot.UnclosedChars0R1, p.cI, first[slot.UnclosedChars0R1])
				break
			}

			p.call(slot.UnclosedChars0R2, cU, p.cI)
		case slot.UnclosedChars0R2: // UnclosedChars : UnclosedChar UnclosedChars ∙

			if p.follow(symbols.NT_UnclosedChars) {
				p.rtn(symbols.NT_UnclosedChars, cU, p.cI)
			} else {
				p.parseError(slot.UnclosedChars0R0, p.cI, followSets[symbols.NT_UnclosedChars])
			}
		case slot.UnclosedChars1R0: // UnclosedChars : ∙
			p.bsrSet.AddEmpty(slot.UnclosedChars1R0, p.cI)

			if p.follow(symbols.NT_UnclosedChars) {
				p.rtn(symbols.NT_UnclosedChars, cU, p.cI)
			} else {
				p.parseError(slot.UnclosedChars1R0, p.cI, followSets[symbols.NT_UnclosedChars])
			}
		case slot.WS0R0: // WS : ∙SpaceOrComment WS

			p.call(slot.WS0R1, cU, p.cI)
		case slot.WS0R1: // WS : SpaceOrComment ∙WS

			if !p.testSelect(slot.WS0R1) {
				p.parseError(slot.WS0R1, p.cI, first[slot.WS0R1])
				break
			}

			p.call(slot.WS0R2, cU, p.cI)
		case slot.WS0R2: // WS : SpaceOrComment WS ∙

			if p.follow(symbols.NT_WS) {
				p.rtn(symbols.NT_WS, cU, p.cI)
			} else {
				p.parseError(slot.WS0R0, p.cI, followSets[symbols.NT_WS])
			}
		case slot.WS1R0: // WS : ∙EMPTY

			p.call(slot.WS1R1, cU, p.cI)
		case slot.WS1R1: // WS : EMPTY ∙

			if p.follow(symbols.NT_WS) {
				p.rtn(symbols.NT_WS, cU, p.cI)
			} else {
				p.parseError(slot.WS1R0, p.cI, followSets[symbols.NT_WS])
			}

		default:
			panic("This must not happen")
		}
	}
	if !p.bsrSet.Contain(symbols.NT_Grammar, 0, m) {
		p.sortParseErrors()
		return nil, p.parseErrors
	}
	return p.bsrSet, nil
}

func (p *parser) ntAdd(nt symbols.NT, j int) {
	// fmt.Printf("p.ntAdd(%s, %d)\n", nt, j)
	failed := true
	expected := map[token.Type]string{}
	for _, l := range slot.GetAlternates(nt) {
		if p.testSelect(l) {
			p.dscAdd(l, j, j)
			failed = false
		} else {
			for k, v := range first[l] {
				expected[k] = v
			}
		}
	}
	if failed {
		for _, l := range slot.GetAlternates(nt) {
			p.parseError(l, j, expected)
		}
	}
}

/*** Call Return Forest ***/

type poppedNode struct {
	X    symbols.NT
	k, j int
}

type clusterNode struct {
	X symbols.NT
	k int
}

type crfNode struct {
	L slot.Label
	i int
}

/*
suppose that L is Y ::=αX ·β
if there is no CRF node labelled (L,i)
	create one let u be the CRF node labelled (L,i)
if there is no CRF node labelled (X, j) {
	create a CRF node v labelled (X, j)
	create an edge from v to u
	ntAdd(X, j)
} else {
	let v be the CRF node labelled (X, j)
	if there is not an edge from v to u {
		create an edge from v to u
		for all ((X, j,h)∈P) {
			dscAdd(L, i, h);
			bsrAdd(L, i, j, h)
		}
	}
}
*/
func (p *parser) call(L slot.Label, i, j int) {
	// fmt.Printf("p.call(%s,%d,%d)\n", L,i,j)
	u, exist := p.crfNodes[crfNode{L, i}]
	// fmt.Printf("  u exist=%t\n", exist)
	if !exist {
		u = &crfNode{L, i}
		p.crfNodes[*u] = u
	}
	X := L.Symbols()[L.Pos()-1].(symbols.NT)
	ndV := clusterNode{X, j}
	v, exist := p.crf[ndV]
	if !exist {
		// fmt.Println("  v !exist")
		p.crf[ndV] = []*crfNode{u}
		p.ntAdd(X, j)
	} else {
		// fmt.Println("  v exist")
		if !existEdge(v, u) {
			// fmt.Printf("  !existEdge(%v)\n", u)
			p.crf[ndV] = append(v, u)
			// fmt.Printf("|popped|=%d\n", len(popped))
			for pnd := range p.popped {
				if pnd.X == X && pnd.k == j {
					p.dscAdd(L, i, pnd.j)
					p.bsrSet.Add(L, i, j, pnd.j)
				}
			}
		}
	}
}

func existEdge(nds []*crfNode, nd *crfNode) bool {
	for _, nd1 := range nds {
		if nd1 == nd {
			return true
		}
	}
	return false
}

func (p *parser) rtn(X symbols.NT, k, j int) {
	// fmt.Printf("p.rtn(%s,%d,%d)\n", X,k,j)
	pn := poppedNode{X, k, j}
	if _, exist := p.popped[pn]; !exist {
		p.popped[pn] = true
		for _, nd := range p.crf[clusterNode{X, k}] {
			p.dscAdd(nd.L, nd.i, j)
			p.bsrSet.Add(nd.L, nd.i, k, j)
		}
	}
}

// func CRFString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("CRF: {")
// 	for cn, nds := range crf{
// 		for _, nd := range nds {
// 			fmt.Fprintf(buf, "%s->%s, ", cn, nd)
// 		}
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

func (cn clusterNode) String() string {
	return fmt.Sprintf("(%s,%d)", cn.X, cn.k)
}

func (n crfNode) String() string {
	return fmt.Sprintf("(%s,%d)", n.L.String(), n.i)
}

// func PoppedString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("Popped: {")
// 	for p, _ := range popped {
// 		fmt.Fprintf(buf, "(%s,%d,%d) ", p.X, p.k, p.j)
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

/*** descriptors ***/

type descriptors struct {
	set []*descriptor
}

func (ds *descriptors) contain(d *descriptor) bool {
	for _, d1 := range ds.set {
		if d1 == d {
			return true
		}
	}
	return false
}

func (ds *descriptors) empty() bool {
	return len(ds.set) == 0
}

func (ds *descriptors) String() string {
	buf := new(bytes.Buffer)
	buf.WriteString("{")
	for i, d := range ds.set {
		if i > 0 {
			buf.WriteString("; ")
		}
		fmt.Fprintf(buf, "%s", d)
	}
	buf.WriteString("}")
	return buf.String()
}

type descriptor struct {
	L slot.Label
	k int
	i int
}

func (d *descriptor) String() string {
	return fmt.Sprintf("%s,%d,%d", d.L, d.k, d.i)
}

func (p *parser) dscAdd(L slot.Label, k, i int) {
	// fmt.Printf("p.dscAdd(%s,%d,%d)\n", L, k, i)
	d := &descriptor{L, k, i}
	if !p.U.contain(d) {
		p.R.set = append(p.R.set, d)
		p.U.set = append(p.U.set, d)
	}
}

func (ds *descriptors) remove() (L slot.Label, k, i int) {
	d := ds.set[len(ds.set)-1]
	ds.set = ds.set[:len(ds.set)-1]
	// fmt.Printf("remove: %s,%d,%d\n", d.L, d.k, d.i)
	return d.L, d.k, d.i
}

func (p *parser) DumpDescriptors() {
	p.DumpR()
	p.DumpU()
}

func (p *parser) DumpR() {
	fmt.Println("R:")
	for _, d := range p.R.set {
		fmt.Printf(" %s\n", d)
	}
}

func (p *parser) DumpU() {
	fmt.Println("U:")
	for _, d := range p.U.set {
		fmt.Printf(" %s\n", d)
	}
}

/*** TestSelect ***/

func (p *parser) follow(nt symbols.NT) bool {
	_, exist := followSets[nt][p.lex.Tokens[p.cI].Type()]
	return exist
}

func (p *parser) testSelect(l slot.Label) bool {
	_, exist := first[l][p.lex.Tokens[p.cI].Type()]
	// fmt.Printf("testSelect(%s) = %t\n", l, exist)
	return exist
}

var first = []map[token.Type]string{
	// AND : ∙& WS
	{
		token.T_1: "&",
	},
	// AND : & ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// AND : & WS ∙
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// ANY : ∙. WS
	{
		token.T_5: ".",
	},
	// ANY : . ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// ANY : . WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CLOSE : ∙( WS
	{
		token.T_2: "(",
	},
	// CLOSE : ( ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// CLOSE : ( WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CharClass : ∙[ UnclosedChars ] WS
	{
		token.T_9: "[",
	},
	// CharClass : [ ∙UnclosedChars ] WS
	{
		token.T_10: "]",
		token.T_19: "notSqBk",
	},
	// CharClass : [ UnclosedChars ∙] WS
	{
		token.T_10: "]",
	},
	// CharClass : [ UnclosedChars ] ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// CharClass : [ UnclosedChars ] WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CharLiteral : ∙sQuote Character sQuote
	{
		token.T_21: "sQuote",
	},
	// CharLiteral : sQuote ∙Character sQuote
	{
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
	},
	// CharLiteral : sQuote Character ∙sQuote
	{
		token.T_21: "sQuote",
	},
	// CharLiteral : sQuote Character sQuote ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Character : ∙notQuotesEsc
	{
		token.T_18: "notQuotesEsc",
	},
	// Character : notQuotesEsc ∙
	{
		token.T_10: "]",
		token.T_12: "dQuote",
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
		token.T_19: "notSqBk",
		token.T_21: "sQuote",
	},
	// Character : ∙esc
	{
		token.T_14: "esc",
	},
	// Character : esc ∙
	{
		token.T_10: "]",
		token.T_12: "dQuote",
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
		token.T_19: "notSqBk",
		token.T_21: "sQuote",
	},
	// Choice : ∙Sequence RepPipedSeq0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Choice : Sequence ∙RepPipedSeq0x
	{
		token.T_23: "|",
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Choice : Sequence RepPipedSeq0x ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// EMPTY : ∙; WS
	{
		token.T_6: ";",
	},
	// EMPTY : ; ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// EMPTY : ; WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_7:  "=",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_17: "neq",
		token.T_20: "num",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// EQUAL : ∙= WS
	{
		token.T_7: "=",
	},
	// EQUAL : = ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// EQUAL : = WS ∙
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Expression : ∙AND Primary
	{
		token.T_1: "&",
	},
	// Expression : AND ∙Primary
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Expression : AND Primary ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Expression : ∙NOT Primary
	{
		token.T_0: "!",
	},
	// Expression : NOT ∙Primary
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Expression : NOT Primary ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Expression : ∙Primary OptStarPlus
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Expression : Primary ∙OptStarPlus
	{
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_8:  "?",
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Expression : Primary OptStarPlus ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Grammar : ∙WS Rule RepRule0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Grammar : WS ∙Rule RepRule0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Grammar : WS Rule ∙RepRule0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.EOF:  "$",
	},
	// Grammar : WS Rule RepRule0x ∙
	{
		token.EOF: "$",
	},
	// Identifier : ∙LetWS LetOrNum0x WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Identifier : LetWS ∙LetOrNum0x WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// Identifier : LetWS LetOrNum0x ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Identifier : LetWS LetOrNum0x WS ∙
	{
		token.T_7:  "=",
		token.T_17: "neq",
	},
	// LetOrNum : ∙let
	{
		token.T_15: "let",
	},
	// LetOrNum : let ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum : ∙num
	{
		token.T_20: "num",
	},
	// LetOrNum : num ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum : ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LetOrNum : WS ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum0x : ∙LetOrNum LetOrNum0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum0x : LetOrNum ∙LetOrNum0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum0x : LetOrNum LetOrNum0x ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LetOrNum0x : ∙EMPTY
	{
		token.T_6: ";",
	},
	// LetOrNum0x : EMPTY ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LetWS : ∙let
	{
		token.T_15: "let",
	},
	// LetWS : let ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetWS : ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LetWS : WS ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LineOrBlock : ∙lineComment
	{
		token.T_16: "lineComment",
	},
	// LineOrBlock : lineComment ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LineOrBlock : ∙blockComment
	{
		token.T_11: "blockComment",
	},
	// LineOrBlock : blockComment ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// NEQUAL : ∙neq WS
	{
		token.T_17: "neq",
	},
	// NEQUAL : neq ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// NEQUAL : neq WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// NOT : ∙! WS
	{
		token.T_0: "!",
	},
	// NOT : ! ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// NOT : ! WS ∙
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// OPEN : ∙( WS
	{
		token.T_2: "(",
	},
	// OPEN : ( ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// OPEN : ( WS ∙
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// OPT : ∙? WS
	{
		token.T_8: "?",
	},
	// OPT : ? ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// OPT : ? WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// OptStarPlus : ∙OPT
	{
		token.T_8: "?",
	},
	// OptStarPlus : OPT ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// OptStarPlus : ∙STAR
	{
		token.T_3: "*",
	},
	// OptStarPlus : STAR ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// OptStarPlus : ∙PLUS
	{
		token.T_4: "+",
	},
	// OptStarPlus : PLUS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// OptStarPlus : ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// PIPE : ∙| WS
	{
		token.T_23: "|",
	},
	// PIPE : | ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// PIPE : | WS ∙
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// PLUS : ∙+ WS
	{
		token.T_4: "+",
	},
	// PLUS : + ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// PLUS : + WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙Identifier NEQUAL
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Primary : Identifier ∙NEQUAL
	{
		token.T_17: "neq",
	},
	// Primary : Identifier NEQUAL ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙OPEN Choice CLOSE
	{
		token.T_2: "(",
	},
	// Primary : OPEN ∙Choice CLOSE
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Primary : OPEN Choice ∙CLOSE
	{
		token.T_2: "(",
	},
	// Primary : OPEN Choice CLOSE ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙StringLiteral
	{
		token.T_12: "dQuote",
	},
	// Primary : StringLiteral ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙CharLiteral
	{
		token.T_21: "sQuote",
	},
	// Primary : CharLiteral ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙CharClass
	{
		token.T_9: "[",
	},
	// Primary : CharClass ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙ANY
	{
		token.T_5: ".",
	},
	// Primary : ANY ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary : ∙EMPTY
	{
		token.T_6: ";",
	},
	// Primary : EMPTY ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepExpr0x : ∙Expression RepExpr0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// RepExpr0x : Expression ∙RepExpr0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepExpr0x : Expression RepExpr0x ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepExpr0x : ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepPipedSeq0x : ∙PIPE Sequence RepPipedSeq0x
	{
		token.T_23: "|",
	},
	// RepPipedSeq0x : PIPE ∙Sequence RepPipedSeq0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// RepPipedSeq0x : PIPE Sequence ∙RepPipedSeq0x
	{
		token.T_23: "|",
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// RepPipedSeq0x : PIPE Sequence RepPipedSeq0x ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// RepPipedSeq0x : ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// RepRule0x : ∙Rule RepRule0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// RepRule0x : Rule ∙RepRule0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.EOF:  "$",
	},
	// RepRule0x : Rule RepRule0x ∙
	{
		token.EOF: "$",
	},
	// RepRule0x : ∙
	{
		token.EOF: "$",
	},
	// Rule : ∙Identifier EQUAL Choice
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// Rule : Identifier ∙EQUAL Choice
	{
		token.T_7: "=",
	},
	// Rule : Identifier EQUAL ∙Choice
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Rule : Identifier EQUAL Choice ∙
	{
		token.EOF:  "$",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// STAR : ∙* WS
	{
		token.T_3: "*",
	},
	// STAR : * ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// STAR : * WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Sequence : ∙Expression RepExpr0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Sequence : Expression ∙RepExpr0x
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Sequence : Expression RepExpr0x ∙
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// SpaceOrComment : ∙space
	{
		token.T_22: "space",
	},
	// SpaceOrComment : space ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// SpaceOrComment : ∙LineOrBlock
	{
		token.T_11: "blockComment",
		token.T_16: "lineComment",
	},
	// SpaceOrComment : LineOrBlock ∙
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// String : ∙Character String
	{
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
	},
	// String : Character ∙String
	{
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
		token.T_12: "dQuote",
	},
	// String : Character String ∙
	{
		token.T_12: "dQuote",
	},
	// String : ∙
	{
		token.T_12: "dQuote",
	},
	// StringLiteral : ∙dQuote String dQuote WS
	{
		token.T_12: "dQuote",
	},
	// StringLiteral : dQuote ∙String dQuote WS
	{
		token.T_12: "dQuote",
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
	},
	// StringLiteral : dQuote String ∙dQuote WS
	{
		token.T_12: "dQuote",
	},
	// StringLiteral : dQuote String dQuote ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// StringLiteral : dQuote String dQuote WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// UnclosedChar : ∙notSqBk Character
	{
		token.T_19: "notSqBk",
	},
	// UnclosedChar : notSqBk ∙Character
	{
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
	},
	// UnclosedChar : notSqBk Character ∙
	{
		token.T_10: "]",
		token.T_19: "notSqBk",
	},
	// UnclosedChars : ∙UnclosedChar UnclosedChars
	{
		token.T_19: "notSqBk",
	},
	// UnclosedChars : UnclosedChar ∙UnclosedChars
	{
		token.T_19: "notSqBk",
		token.T_10: "]",
	},
	// UnclosedChars : UnclosedChar UnclosedChars ∙
	{
		token.T_10: "]",
	},
	// UnclosedChars : ∙
	{
		token.T_10: "]",
	},
	// WS : ∙SpaceOrComment WS
	{
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// WS : SpaceOrComment ∙WS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// WS : SpaceOrComment WS ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_7:  "=",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_17: "neq",
		token.T_20: "num",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// WS : ∙EMPTY
	{
		token.T_6: ";",
	},
	// WS : EMPTY ∙
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_7:  "=",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_17: "neq",
		token.T_20: "num",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
}

var followSets = []map[token.Type]string{
	// AND
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// ANY
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CLOSE
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CharClass
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// CharLiteral
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Character
	{
		token.T_10: "]",
		token.T_12: "dQuote",
		token.T_14: "esc",
		token.T_18: "notQuotesEsc",
		token.T_19: "notSqBk",
		token.T_21: "sQuote",
	},
	// Choice
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// EMPTY
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_7:  "=",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_17: "neq",
		token.T_20: "num",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// EQUAL
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// Expression
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Grammar
	{
		token.EOF: "$",
	},
	// Identifier
	{
		token.T_7:  "=",
		token.T_17: "neq",
	},
	// LetOrNum
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LetOrNum0x
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// LetWS
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_20: "num",
		token.T_22: "space",
	},
	// LineOrBlock
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// NEQUAL
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// NOT
	{
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// OPEN
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// OPT
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// OptStarPlus
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// PIPE
	{
		token.T_0:  "!",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
	},
	// PLUS
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Primary
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepExpr0x
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// RepPipedSeq0x
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// RepRule0x
	{
		token.EOF: "$",
	},
	// Rule
	{
		token.EOF:  "$",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// STAR
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// Sequence
	{
		token.EOF:  "$",
		token.T_2:  "(",
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_22: "space",
		token.T_23: "|",
	},
	// SpaceOrComment
	{
		token.T_6:  ";",
		token.T_11: "blockComment",
		token.T_16: "lineComment",
		token.T_22: "space",
	},
	// String
	{
		token.T_12: "dQuote",
	},
	// StringLiteral
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
	// UnclosedChar
	{
		token.T_10: "]",
		token.T_19: "notSqBk",
	},
	// UnclosedChars
	{
		token.T_10: "]",
	},
	// WS
	{
		token.T_0:  "!",
		token.EOF:  "$",
		token.T_1:  "&",
		token.T_2:  "(",
		token.T_3:  "*",
		token.T_4:  "+",
		token.T_5:  ".",
		token.T_6:  ";",
		token.T_7:  "=",
		token.T_8:  "?",
		token.T_9:  "[",
		token.T_11: "blockComment",
		token.T_12: "dQuote",
		token.T_15: "let",
		token.T_16: "lineComment",
		token.T_17: "neq",
		token.T_20: "num",
		token.T_21: "sQuote",
		token.T_22: "space",
		token.T_23: "|",
	},
}

/*** Errors ***/

/*
Error is returned by Parse at every point at which the parser fails to parse
a grammar production. For non-LL-1 grammars there will be an error for each
alternate attempted by the parser.

The errors are sorted in descending order of input position (index of token in
the stream of tokens).

Normally the error of interest is the one that has parsed the largest number of
tokens.
*/
type Error struct {
	// Index of token that caused the error.
	cI int

	// Grammar slot at which the error occured.
	Slot slot.Label

	// The token at which the error occurred.
	Token *token.Token

	// The line and column in the input text at which the error occurred
	Line, Column int

	// The tokens expected at the point where the error occurred
	Expected map[token.Type]string
}

func (pe *Error) String() string {
	w := new(bytes.Buffer)
	fmt.Fprintf(w, "Parse Error: %s I[%d]=%s at line %d col %d\n",
		pe.Slot, pe.cI, pe.Token, pe.Line, pe.Column)
	exp := []string{}
	for _, e := range pe.Expected {
		exp = append(exp, e)
	}
	fmt.Fprintf(w, "Expected one of: [%s]", strings.Join(exp, ","))
	return w.String()
}

func (p *parser) parseError(slot slot.Label, i int, expected map[token.Type]string) {
	pe := &Error{cI: i, Slot: slot, Token: p.lex.Tokens[i], Expected: expected}
	p.parseErrors = append(p.parseErrors, pe)
}

func (p *parser) sortParseErrors() {
	sort.Slice(p.parseErrors,
		func(i, j int) bool {
			return p.parseErrors[j].Token.Lext() < p.parseErrors[i].Token.Lext()
		})
	for _, pe := range p.parseErrors {
		pe.Line, pe.Column = p.lex.GetLineColumn(pe.Token.Lext())
	}
}
